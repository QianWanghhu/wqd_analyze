{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script is used to caclulate the Event Mean Concentration (EMC).\n",
    "The inputs are .csv files containing concentration and flow after linear interpolation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.concentration import rainfall_events, emc_cal, conc_interpolate, event_emc\n",
    "import datetime\n",
    "\n",
    "# read the discrete storm events\n",
    "# Read daily loads and flow\n",
    "# Read hourly loads and flow\n",
    "from common_settings import obspath, outpath, events_name, \\\n",
    "    obs_events, day_load_flow, hour_load_flow, conct_name, modpath, mod_load_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.concentration import cumulative_lq, excel_save\n",
    "from utils.signatures import update_cumul_df, load_flow_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the event mean concentration of obs and mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for low-frequency data\n",
    "cols = [col for col in day_load_flow.columns if ('Load' in col) or ('Flow(ML)' in col)]\n",
    "index_range1 = [1, 38]\n",
    "index_range2 = [60, obs_events.shape[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events = event_emc(obs_events, day_load_flow, index_range1, cols[0], cols[1], \n",
    "    time_scale='d', multiplier=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for high-frequency data\n",
    "cols = [col for col in hour_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range2 = [60, obs_events.shape[0]+1]\n",
    "loads_col = cols[1]; flow_col = cols[0]\n",
    "obs_events = event_emc(obs_events, hour_load_flow, index_range2, loads_col, flow_col, \n",
    "    time_scale='h', multiplier=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(outpath + events_name, index='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the discrete storm events\n",
    "filename = 'mod_storm_event_common.csv'\n",
    "events = rainfall_events(f'{modpath}{filename}')\n",
    "# Calculate EMC for modeling data\n",
    "cols = [col for col in mod_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range = [1, events.shape[0]+1]\n",
    "loads_col = cols[0]; flow_col = cols[1]\n",
    "\n",
    "events = event_emc(events, mod_load_flow, index_range, loads_col, flow_col, \n",
    "    time_scale='d', multiplier=1)\n",
    "events.dropna(axis=0, inplace=True)\n",
    "events.to_csv(f'{outpath}DIN_{filename}', index='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>emc(mg/l)</th>\n",
       "      <th>Load(kg)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009/12/28</td>\n",
       "      <td>2010/1/8</td>\n",
       "      <td>0.448745</td>\n",
       "      <td>2661.157144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/1/9</td>\n",
       "      <td>2010/1/14</td>\n",
       "      <td>0.134180</td>\n",
       "      <td>272.049645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/1/24</td>\n",
       "      <td>2010/1/30</td>\n",
       "      <td>0.132544</td>\n",
       "      <td>5411.910178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/1/31</td>\n",
       "      <td>2010/2/9</td>\n",
       "      <td>0.136031</td>\n",
       "      <td>9235.627039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010/2/10</td>\n",
       "      <td>2010/2/16</td>\n",
       "      <td>0.132676</td>\n",
       "      <td>4811.153024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010/2/17</td>\n",
       "      <td>2010/2/25</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>9735.764855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010/2/26</td>\n",
       "      <td>2010/3/5</td>\n",
       "      <td>0.142642</td>\n",
       "      <td>7713.480796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010/3/20</td>\n",
       "      <td>2010/4/5</td>\n",
       "      <td>0.144418</td>\n",
       "      <td>8768.334014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010/8/10</td>\n",
       "      <td>2010/8/25</td>\n",
       "      <td>0.504586</td>\n",
       "      <td>507.639623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010/9/19</td>\n",
       "      <td>2010/10/12</td>\n",
       "      <td>0.301528</td>\n",
       "      <td>1793.671799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010/11/15</td>\n",
       "      <td>2010/11/29</td>\n",
       "      <td>0.194897</td>\n",
       "      <td>9472.503647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010/11/30</td>\n",
       "      <td>2010/12/12</td>\n",
       "      <td>0.166626</td>\n",
       "      <td>13631.326935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010/12/23</td>\n",
       "      <td>2010/12/29</td>\n",
       "      <td>0.166794</td>\n",
       "      <td>16399.820357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010/12/30</td>\n",
       "      <td>2011/1/2</td>\n",
       "      <td>0.152480</td>\n",
       "      <td>3742.931842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011/1/3</td>\n",
       "      <td>2011/1/12</td>\n",
       "      <td>0.163098</td>\n",
       "      <td>4430.006433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011/1/30</td>\n",
       "      <td>2011/2/10</td>\n",
       "      <td>0.141378</td>\n",
       "      <td>6476.506022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011/2/11</td>\n",
       "      <td>2011/2/15</td>\n",
       "      <td>0.094658</td>\n",
       "      <td>777.206317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011/2/16</td>\n",
       "      <td>2011/2/22</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>742.571819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011/3/12</td>\n",
       "      <td>2011/3/24</td>\n",
       "      <td>0.091036</td>\n",
       "      <td>8947.630071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011/3/25</td>\n",
       "      <td>2011/4/8</td>\n",
       "      <td>0.097876</td>\n",
       "      <td>15602.252833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012/1/14</td>\n",
       "      <td>2012/1/23</td>\n",
       "      <td>0.357545</td>\n",
       "      <td>833.111702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012/1/23</td>\n",
       "      <td>2012/2/14</td>\n",
       "      <td>0.160449</td>\n",
       "      <td>4650.740262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012/2/24</td>\n",
       "      <td>2012/3/13</td>\n",
       "      <td>0.150407</td>\n",
       "      <td>6680.193114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012/3/14</td>\n",
       "      <td>2012/4/5</td>\n",
       "      <td>0.138076</td>\n",
       "      <td>32455.144301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012/5/21</td>\n",
       "      <td>2012/6/8</td>\n",
       "      <td>0.513410</td>\n",
       "      <td>2294.622720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012/7/8</td>\n",
       "      <td>2012/7/28</td>\n",
       "      <td>0.206211</td>\n",
       "      <td>4060.094226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012/12/22</td>\n",
       "      <td>2013/1/19</td>\n",
       "      <td>0.369483</td>\n",
       "      <td>1295.462596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013/1/24</td>\n",
       "      <td>2013/2/13</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>8652.130257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013/2/14</td>\n",
       "      <td>2013/2/26</td>\n",
       "      <td>0.144589</td>\n",
       "      <td>2549.002898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013/2/27</td>\n",
       "      <td>2013/3/18</td>\n",
       "      <td>0.135125</td>\n",
       "      <td>17876.286978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2013/4/6</td>\n",
       "      <td>2013/4/23</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>4884.865122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2014/1/9</td>\n",
       "      <td>2014/1/26</td>\n",
       "      <td>0.340835</td>\n",
       "      <td>1024.105183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2014/1/30</td>\n",
       "      <td>2014/2/9</td>\n",
       "      <td>0.285273</td>\n",
       "      <td>3297.732459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014/2/10</td>\n",
       "      <td>2014/2/18</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>1217.121730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2014/2/19</td>\n",
       "      <td>2014/2/25</td>\n",
       "      <td>0.227933</td>\n",
       "      <td>1865.544750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2014/3/21</td>\n",
       "      <td>2014/4/12</td>\n",
       "      <td>0.161301</td>\n",
       "      <td>5174.677692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2014/4/13</td>\n",
       "      <td>2014/4/27</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>5431.081208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start         end  emc(mg/l)      Load(kg)\n",
       "ID                                                 \n",
       "1   2009/12/28    2010/1/8   0.448745   2661.157144\n",
       "2     2010/1/9   2010/1/14   0.134180    272.049645\n",
       "3    2010/1/24   2010/1/30   0.132544   5411.910178\n",
       "4    2010/1/31    2010/2/9   0.136031   9235.627039\n",
       "5    2010/2/10   2010/2/16   0.132676   4811.153024\n",
       "6    2010/2/17   2010/2/25   0.137715   9735.764855\n",
       "7    2010/2/26    2010/3/5   0.142642   7713.480796\n",
       "8    2010/3/20    2010/4/5   0.144418   8768.334014\n",
       "9    2010/8/10   2010/8/25   0.504586    507.639623\n",
       "10   2010/9/19  2010/10/12   0.301528   1793.671799\n",
       "11  2010/11/15  2010/11/29   0.194897   9472.503647\n",
       "12  2010/11/30  2010/12/12   0.166626  13631.326935\n",
       "13  2010/12/23  2010/12/29   0.166794  16399.820357\n",
       "14  2010/12/30    2011/1/2   0.152480   3742.931842\n",
       "15    2011/1/3   2011/1/12   0.163098   4430.006433\n",
       "16   2011/1/30   2011/2/10   0.141378   6476.506022\n",
       "17   2011/2/11   2011/2/15   0.094658    777.206317\n",
       "18   2011/2/16   2011/2/22   0.087830    742.571819\n",
       "19   2011/3/12   2011/3/24   0.091036   8947.630071\n",
       "20   2011/3/25    2011/4/8   0.097876  15602.252833\n",
       "21   2012/1/14   2012/1/23   0.357545    833.111702\n",
       "22   2012/1/23   2012/2/14   0.160449   4650.740262\n",
       "23   2012/2/24   2012/3/13   0.150407   6680.193114\n",
       "24   2012/3/14    2012/4/5   0.138076  32455.144301\n",
       "25   2012/5/21    2012/6/8   0.513410   2294.622720\n",
       "26    2012/7/8   2012/7/28   0.206211   4060.094226\n",
       "27  2012/12/22   2013/1/19   0.369483   1295.462596\n",
       "28   2013/1/24   2013/2/13   0.161306   8652.130257\n",
       "29   2013/2/14   2013/2/26   0.144589   2549.002898\n",
       "30   2013/2/27   2013/3/18   0.135125  17876.286978\n",
       "31    2013/4/6   2013/4/23   0.177975   4884.865122\n",
       "32    2014/1/9   2014/1/26   0.340835   1024.105183\n",
       "33   2014/1/30    2014/2/9   0.285273   3297.732459\n",
       "34   2014/2/10   2014/2/18   0.235938   1217.121730\n",
       "35   2014/2/19   2014/2/25   0.227933   1865.544750\n",
       "36   2014/3/21   2014/4/12   0.161301   5174.677692\n",
       "37   2014/4/13   2014/4/27   0.556250   5431.081208"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the Normalized cumulative ratio of loads and flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the daily data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2020)]\n",
    "# time_ranges = obs_events.loc[:, ['start', 'end']].values\n",
    "double_mass_ratio = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(0, len(time_ranges)-2):\n",
    "# for ii in range(index_range1[0]-1, index_range1[1]-1):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], day_load_flow, timestep='d')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, 0], df_temp.values[:, -1])\n",
    "    double_mass_ratio[f'obs_year_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outputs into one excel\n",
    "fn = outpath +'obs_year_cumulative_ratio_day.xlsx'\n",
    "excel_save(double_mass_ratio, fn, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the hourly data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_mass_ratio = {}\n",
    "for ii in range(index_range2[0]-1, index_range2[1]-1):\n",
    "# for ii in range(9, len(time_ranges)):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], hour_load_flow, timestep='h')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, -1], df_temp.values[:, 0])\n",
    "    double_mass_ratio[f'obs_storm_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outputs into one excel\n",
    "fn = outpath +'obs_storm_cumulative_ratio_hour.xlsx'\n",
    "excel_save(double_mass_ratio, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the modeling data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpath = '../data/mod/'\n",
    "filename = 'storm_event.csv'\n",
    "mod_events = rainfall_events(f'{modpath}{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for modeling data\n",
    "cols = [col for col in mod_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range = [1, mod_events.shape[0]]\n",
    "loads_col = cols[0]; flow_col = cols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\oed\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "F:\\Anaconda\\envs\\oed\\lib\\site-packages\\pandas\\core\\indexing.py:1783: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "double_mass_ratio = {}\n",
    "# time_ranges = [[f'{year}-07-01', f'{year+1}-06-30'] for year in range(2009, 2014)]\n",
    "time_ranges = mod_events.loc[:, ['start', 'end']].values\n",
    "for ii in range(index_range[0], index_range[1]):\n",
    "# for ii in range(len(time_ranges)):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], mod_load_flow, timestep='d')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, 0], df_temp.values[:, -1])\n",
    "    double_mass_ratio[f'mod_storm_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "fn = outpath +'mod_storm_cumulative_ratio_day.xlsx'\n",
    "excel_save(double_mass_ratio, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate event load coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event loads for obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_fn = 'obs_storm_event_common'\n",
    "obs_events = pd.read_csv(f'{outpath}{obs_event_fn}.csv', index_col = 'ID') \n",
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, calculate the yearly loads \n",
    "year_loads = {}\n",
    "# obs daily data\n",
    "for tt in time_ranges[0:-2]:\n",
    "    df = load_flow_loc(tt, day_load_flow, timestep='d')\n",
    "    year_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  \n",
    "    \n",
    "# # obs hourly data\n",
    "# for tt in time_ranges[-2:]:\n",
    "#     df = load_flow_loc(tt, hour_load_flow, timestep='h')\n",
    "#     year_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event load coefficients\n",
    "for ii in range(1, index_range1[1]):\n",
    "    df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, day_load_flow, timestep='d')\n",
    "    ymd= pd.to_datetime(obs_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year - 1)]\n",
    "    else:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year)]\n",
    "        \n",
    "# for ii in range(index_range2[0], index_range2[1]):\n",
    "#     df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, hour_load_flow, timestep='h')\n",
    "#     ymd= pd.to_datetime(obs_events.loc[ii, 'start'])\n",
    "#     month = ymd.month; year = ymd.year\n",
    "#     if month < 7:\n",
    "#         obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year-1)]\n",
    "#     else:\n",
    "#         obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(f'{outpath}{obs_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event loads for mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_event_fn = 'DIN_mod_storm_event_common'\n",
    "mod_events = pd.read_csv(f'{outpath}{mod_event_fn}.csv', index_col = 'ID') \n",
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, calculate the yearly loads \n",
    "mod_loads = {}\n",
    "# mod daily data\n",
    "for tt in time_ranges:\n",
    "    df = load_flow_loc(tt, mod_load_flow, timestep='d')\n",
    "    mod_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event load coefficients\n",
    "for ii in mod_events.index:\n",
    "    df_event = load_flow_loc(mod_events.loc[ii, 'start':'end'].values, mod_load_flow, timestep='d')\n",
    "    ymd= pd.to_datetime(mod_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        mod_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / mod_loads[str(year - 1)]\n",
    "    else:\n",
    "        mod_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / mod_loads[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_events.to_csv(f'{outpath}{mod_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the peaktime difference between flow and loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_event_fn = 'DIN_mod_storm_event_common'\n",
    "mod_events = pd.read_csv(f'{outpath}{mod_event_fn}.csv', index_col = 'ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the peak time of loads\n",
    "for ii in mod_events.index:\n",
    "    df_event = load_flow_loc(mod_events.loc[ii, 'start':'end'].values, mod_load_flow, timestep='d')\n",
    "    peaktime_load = df_event[df_event.loc[:, 'Loads (kg)']==df_event.loc[:, 'Loads (kg)'].max()].index\n",
    "    mod_events.loc[ii, 'peaktime_load'] = peaktime_load\n",
    "    mod_events.loc[ii, 'peakflow'] = df_event.loc[:, 'Flow_cumecs (ML.day^-1)'].max()\n",
    "    mod_events.loc[ii, 'peaktime'] = df_event[df_event.loc[:, 'Flow_cumecs (ML.day^-1)']==df_event.loc[:, 'Flow_cumecs (ML.day^-1)'].max()].index\n",
    "    \n",
    "mod_events.loc[:, 'delta_time'] = mod_events.peaktime_load - mod_events.peaktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_events.to_csv(f'{outpath}{mod_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_fn = 'obs_storm_event_common'\n",
    "obs_events = pd.read_csv(f'{outpath}{obs_event_fn}.csv', index_col = 'ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the peak time of loads\n",
    "for ii in obs_events.index:\n",
    "    df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, day_load_flow, timestep='d')\n",
    "    peaktime_load = df_event[df_event.loc[:, 'Linear_Average_Load(t)']==df_event.loc[:, 'Linear_Average_Load(t)'].max()].index\n",
    "    obs_events.loc[ii, 'peaktime_load'] = peaktime_load\n",
    "    obs_events.loc[ii, 'peakflow'] = df_event.loc[:, 'Flow(ML)'].max()\n",
    "    obs_events.loc[ii, 'peaktime'] = df_event[df_event.loc[:, 'Flow(ML)']==df_event.loc[:, 'Flow(ML)'].max()].index\n",
    "    \n",
    "obs_events.loc[:, 'delta_time'] = pd.to_datetime(obs_events.peaktime_load) - pd.to_datetime(obs_events.peaktime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(f'{outpath}{obs_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variability of load-discharge ratio (seasonal average concentration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year}/10/1', f'{year+1}/1/1', f'{year+1}/4/1', f'{year+1}/7/1'] for year in range(2009, 2014)]\n",
    "df_ratio = pd.DataFrame(index=[str(year) for year in range(2009, 2014)], columns = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in time_ranges:\n",
    "    for ii in range(len(tt) -1):\n",
    "        start = pd.to_datetime(tt[ii])\n",
    "        end = pd.to_datetime(tt[ii + 1]) - datetime.timedelta(days=1)   \n",
    "        df = load_flow_loc([start, end], day_load_flow, timestep ='d')\n",
    "        df_ratio.loc[tt[0][0:4], ii+1] = df.sum(axis=0)[0] / df.sum(axis=0)[2] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio.to_csv(f'{outpath}obs_seasonal_concentration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year}/10/1', f'{year+1}/1/1', f'{year+1}/4/1', f'{year+1}/7/1'] for year in range(2009, 2014)]\n",
    "df_ratio = pd.DataFrame(index=[str(year) for year in range(2009, 2014)], columns = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plot()\n",
    "for tt in time_ranges:\n",
    "    for ii in range(len(tt) -1):\n",
    "        start = pd.to_datetime(tt[ii])\n",
    "        end = pd.to_datetime(tt[ii + 1]) - datetime.timedelta(days=1)   \n",
    "        df = load_flow_loc([start, end], mod_load_flow, timestep ='d')\n",
    "        df_ratio.loc[tt[0][0:4], ii+1] = df.sum(axis=0)[0] / df.sum(axis=0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio.to_csv(f'{outpath}mod_seasonal_concentration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oed)",
   "language": "python",
   "name": "oed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

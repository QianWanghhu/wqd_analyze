{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script is used to caclulate the Event Mean Concentration (EMC).\n",
    "The inputs are .csv files containing concentration and flow after linear interpolation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.concentration import rainfall_events, emc_cal, conc_interpolate, event_emc\n",
    "import datetime\n",
    "\n",
    "# read the discrete storm events\n",
    "# Read daily loads and flow\n",
    "# Read hourly loads and flow\n",
    "from common_settings import obspath, outpath, events_name, \\\n",
    "    obs_events, day_load_flow, hour_load_flow, conct_name, modpath, mod_load_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.concentration import cumulative_lq, excel_save\n",
    "from utils.signatures import update_cumul_df, load_flow_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the event mean concentration of obs and mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for low-frequency data\n",
    "cols = [col for col in day_load_flow.columns if ('Load' in col) or ('Flow(ML)' in col)]\n",
    "index_range1 = [1, 38]\n",
    "index_range2 = [38, obs_events.shape[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events = event_emc(obs_events, day_load_flow, index_range1, cols[0], cols[1], \n",
    "    time_scale='d', multiplier=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for high-frequency data\n",
    "cols = [col for col in hour_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range2 = [38, obs_events.shape[0]+1]\n",
    "loads_col = cols[1]; flow_col = cols[0]\n",
    "obs_events = event_emc(obs_events, hour_load_flow, index_range2, loads_col, flow_col, \n",
    "    time_scale='h', multiplier=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(outpath + events_name, index='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the discrete storm events\n",
    "filename = 'mod_storm_event_common.csv'\n",
    "events = rainfall_events(f'{modpath}{filename}')\n",
    "# Calculate EMC for modeling data\n",
    "cols = [col for col in mod_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range = [1, events.shape[0]+1]\n",
    "loads_col = cols[0]; flow_col = cols[1]\n",
    "\n",
    "events = event_emc(events, mod_load_flow, index_range, loads_col, flow_col, \n",
    "    time_scale='d', multiplier=1)\n",
    "events.dropna(axis=0, inplace=True)\n",
    "events.to_csv(f'{outpath}DIN_{filename}', index='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the Normalized cumulative ratio of loads and flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the daily data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2020)]\n",
    "# time_ranges = obs_events.loc[:, ['start', 'end']].values\n",
    "double_mass_ratio = {}\n",
    "annual_total = pd.DataFrame(columns=day_load_flow.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(0, len(time_ranges)-2):\n",
    "# for ii in range(index_range1[0]-1, index_range1[1]-1):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], day_load_flow, timestep='d')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, 0], df_temp.values[:, -2])\n",
    "    double_mass_ratio[f'obs_year_{ii}'] = df_temp\n",
    "    annual_total.loc[time_ranges[ii][0][0:4]] = df_temp.sum(axis=0)\n",
    "annual_total.loc['ave'] = annual_total.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outputs into one excel\n",
    "annual_total.to_csv(outpath+'obs_annual_sum.csv')\n",
    "fn = outpath +'obs_year_cumulative_ratio_day.xlsx'\n",
    "excel_save(double_mass_ratio, fn, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the hourly data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_mass_ratio = {}\n",
    "for ii in range(index_range2[0]-1, index_range2[1]-1):\n",
    "# for ii in range(9, len(time_ranges)):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], hour_load_flow, timestep='h')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, -1], df_temp.values[:, 0])\n",
    "    double_mass_ratio[f'obs_storm_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outputs into one excel\n",
    "fn = outpath +'obs_storm_cumulative_ratio_hour.xlsx'\n",
    "excel_save(double_mass_ratio, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the modeling data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpath = '../data/mod/'\n",
    "annual_total = pd.DataFrame(columns=mod_load_flow.columns)\n",
    "# filename = 'storm_event.csv'\n",
    "# mod_events = rainfall_events(f'{modpath}{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for modeling data\n",
    "cols = [col for col in mod_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "# index_range = [1, mod_events.shape[0]]\n",
    "loads_col = cols[0]; flow_col = cols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_mass_ratio = {}\n",
    "time_ranges = [[f'{year}-07-01', f'{year+1}-06-30'] for year in range(2009, 2018)]\n",
    "# time_ranges = mod_events.loc[:, ['start', 'end']].values\n",
    "# for ii in range(index_range[0], index_range[1]):\n",
    "for ii in range(len(time_ranges)):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], mod_load_flow, timestep='d')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, 0], df_temp.values[:, -1])\n",
    "    double_mass_ratio[f'mod_storm_{ii}'] = df_temp\n",
    "    annual_total.loc[time_ranges[ii][0][0:4]] = df_temp.sum(axis=0)\n",
    "annual_total.loc['ave'] = annual_total.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "annual_total.to_csv(outpath+'mod_annual_sum.csv')\n",
    "\n",
    "fn = outpath +'mod_year_cumulative_ratio_day.xlsx'\n",
    "excel_save(double_mass_ratio, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate event load coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event loads for obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_fn = 'obs_storm_event_common'\n",
    "obs_events = pd.read_csv(f'{outpath}{obs_event_fn}.csv', index_col = 'ID') \n",
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in [2009, 2010, 2011, 2012, 2013, 2014, 2018, 2019]]\n",
    "year_loads = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, calculate the yearly loads \n",
    "# obs daily data\n",
    "for tt in time_ranges[0:-2]:\n",
    "    df = load_flow_loc(tt, day_load_flow, timestep='d')\n",
    "    year_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  \n",
    "    \n",
    "# obs hourly data\n",
    "for tt in time_ranges[-2:]:\n",
    "    df = load_flow_loc(tt, hour_load_flow, timestep='h')\n",
    "    year_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event load coefficients\n",
    "for ii in range(1, index_range1[1]):\n",
    "    df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, day_load_flow, timestep='d')\n",
    "    ymd= pd.to_datetime(obs_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year - 1)]\n",
    "    else:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year)]\n",
    "        \n",
    "for ii in range(index_range2[0], index_range2[1]):\n",
    "    df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, hour_load_flow, timestep='h')\n",
    "    ymd= pd.to_datetime(obs_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year-1)]\n",
    "    else:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(f'{outpath}{obs_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event loads for mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_event_fn = 'DIN_mod_storm_event_common'\n",
    "mod_events = pd.read_csv(f'{outpath}{mod_event_fn}.csv', index_col = 'ID') \n",
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, calculate the yearly loads \n",
    "mod_loads = {}\n",
    "# mod daily data\n",
    "for tt in time_ranges:\n",
    "    df = load_flow_loc(tt, mod_load_flow, timestep='d')\n",
    "    mod_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event load coefficients\n",
    "for ii in mod_events.index:\n",
    "    df_event = load_flow_loc(mod_events.loc[ii, 'start':'end'].values, mod_load_flow, timestep='d')\n",
    "    ymd= pd.to_datetime(mod_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        mod_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / mod_loads[str(year - 1)]\n",
    "    else:\n",
    "        mod_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / mod_loads[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_events.to_csv(f'{outpath}{mod_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the peaktime difference between flow and loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_event_fn = 'DIN_mod_storm_event_common'\n",
    "mod_events = pd.read_csv(f'{outpath}{mod_event_fn}.csv', index_col = 'ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the peak time of loads\n",
    "clabel, llabel, qlabel = ['Downstream Flow Concentration (mg.L^-1)', 'Loads (kg)', 'Flow_cumecs (ML.day^-1)']\n",
    "for ii in mod_events.index:\n",
    "    df_event = load_flow_loc(mod_events.loc[ii, 'start':'end'].values, mod_load_flow, timestep='d')\n",
    "    peaktime_load = df_event[df_event.loc[:, llabel]==df_event.loc[:, llabel].max()].index\n",
    "    peaktime_conc = df_event[df_event.loc[:, clabel]==df_event.loc[:, clabel].max()].index[0]\n",
    "    \n",
    "    mod_events.loc[ii, 'peaktime_load'] = peaktime_load\n",
    "    mod_events.loc[ii, 'peaktime_conc'] = peaktime_conc\n",
    "    mod_events.loc[ii, 'peakflow'] = df_event.loc[:, qlabel].max()\n",
    "    mod_events.loc[ii, 'peaktime'] = df_event[df_event.loc[:, qlabel]==df_event.loc[:, qlabel].max()].index\n",
    "    mod_events.loc[ii, 'peak_flow_time'] = df_event[df_event.loc[:, qlabel]==df_event.loc[:, qlabel].max()].index[0]\n",
    "    mod_events.loc[ii, 'peak_conc_time'] = df_event[df_event.loc[:, clabel]==df_event.loc[:, clabel].max()].index[0]\n",
    "    mod_events.loc[ii, 'peak_load_time'] = df_event[df_event.loc[:, llabel]==df_event.loc[:, llabel].max()].index[0]\n",
    "    \n",
    "# mod_events.loc[:, 'delta_time'] = mod_events.peaktime_load - mod_events.peaktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_events.loc[:, 'delta_load_flow_time'] = pd.to_datetime(mod_events.peak_load_time) - pd.to_datetime(mod_events.peak_flow_time)\n",
    "mod_events.loc[:, 'delta_conc_flow_time'] = pd.to_datetime(mod_events.peak_conc_time) - pd.to_datetime(mod_events.peak_flow_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_events.to_csv(f'{outpath}{mod_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_fn = 'obs_storm_event_common'\n",
    "obs_events = pd.read_csv(f'{outpath}{obs_event_fn}.csv', index_col = 'ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\oed\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:129: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n",
      "F:\\Anaconda\\envs\\oed\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:129: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n",
      "F:\\Anaconda\\envs\\oed\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:129: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n",
      "F:\\Anaconda\\envs\\oed\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:129: FutureWarning: In the future, 'NAT == x' and 'x == NAT' will always be False.\n",
      "  unique_elements = set(islice(arg, check_count))\n"
     ]
    }
   ],
   "source": [
    "# find the peak time of loads\n",
    "for ii in obs_events.index:\n",
    "    if ii < 38:\n",
    "        df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, day_load_flow, timestep='d')\n",
    "        clabel, llabel, qlabel = ['Concentration (mg/L)', 'Linear_Average_Load(t)', 'Flow(ML)']\n",
    "    else:\n",
    "        clabel, llabel, qlabel = ['126001A-NO3(mg/l)', 'Loads (kg)', 'Flow (ML)']\n",
    "        df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, hour_load_flow, timestep='h')\n",
    "    peaktime_load = df_event[df_event.loc[:, llabel]==df_event.loc[:, llabel].max()].index[0]\n",
    "    peaktime_conc = df_event[df_event.loc[:, clabel]==df_event.loc[:, clabel].max()].index[0]\n",
    "\n",
    "    obs_events.loc[ii, 'peaktime_load'] = peaktime_load\n",
    "    obs_events.loc[ii, 'peaktime_conc'] = peaktime_conc\n",
    "    obs_events.loc[ii, 'peakflow'] = df_event.loc[:, qlabel].max()\n",
    "    obs_events.loc[ii, 'peak_flow_time'] = df_event[df_event.loc[:, qlabel]==df_event.loc[:, qlabel].max()].index[0]\n",
    "    obs_events.loc[ii, 'peak_conc_time'] = df_event[df_event.loc[:, clabel]==df_event.loc[:, clabel].max()].index[0]\n",
    "    obs_events.loc[ii, 'peak_load_time'] = df_event[df_event.loc[:, llabel]==df_event.loc[:, llabel].max()].index[0]\n",
    "    \n",
    "obs_events.loc[:, 'delta_load_flow_time'] = pd.to_datetime(obs_events.peak_load_time) - pd.to_datetime(obs_events.peak_flow_time)\n",
    "obs_events.loc[:, 'delta_conc_flow_time'] = pd.to_datetime(obs_events.peak_conc_time) - pd.to_datetime(obs_events.peak_flow_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(f'{outpath}{obs_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variability of load-discharge ratio (seasonal average concentration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year}/10/1', f'{year+1}/1/1', f'{year+1}/4/1', f'{year+1}/7/1'] for year in range(2009, 2018)]\n",
    "df_ratio = pd.DataFrame(index=[str(year) for year in range(2009, 2018)], columns = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in time_ranges:\n",
    "    for ii in range(len(tt) -1):\n",
    "        start = pd.to_datetime(tt[ii])\n",
    "        end = pd.to_datetime(tt[ii + 1]) - datetime.timedelta(days=1)   \n",
    "        df = load_flow_loc([start, end], day_load_flow, timestep ='d')\n",
    "        df_ratio.loc[tt[0][0:4], ii+1] = df.sum(axis=0)[0] / df.sum(axis=0)[2] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio.to_csv(f'{outpath}obs_seasonal_concentration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year}/10/1', f'{year+1}/1/1', f'{year+1}/4/1', f'{year+1}/7/1'] for year in range(2009, 2018)]\n",
    "df_ratio = pd.DataFrame(index=[str(year) for year in range(2009, 2018)], columns = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in time_ranges:\n",
    "    for ii in range(len(tt) -1):\n",
    "        start = pd.to_datetime(tt[ii])\n",
    "        end = pd.to_datetime(tt[ii + 1]) - datetime.timedelta(days=1)   \n",
    "        df = load_flow_loc([start, end], mod_load_flow, timestep ='d')\n",
    "        df_ratio.loc[tt[0][0:4], ii+1] = df.sum(axis=0)[0] / df.sum(axis=0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio.to_csv(f'{outpath}mod_seasonal_concentration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = pd.DataFrame(columns = ['obs', 'mod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the monthly loads and flow\n",
    "for y in range(2009, 2019):\n",
    "    for m in range(1, 13):\n",
    "        start = pd.to_datetime(f'{y}/{m}/1')\n",
    "        if m == 12:\n",
    "            end = pd.to_datetime(f'{y+1}/1/1') - datetime.timedelta(days=1) \n",
    "        else:\n",
    "            end = pd.to_datetime(f'{y}/{m+1}/1') - datetime.timedelta(days=1)\n",
    "            \n",
    "        df_month.loc[f'{y}/{m}', 'obs'] = 1000 * load_flow_loc([start, end], day_load_flow, timestep ='d').sum(axis=0)[0]\n",
    "        df_month.loc[f'{y}/{m}', 'mod'] = load_flow_loc([start, end], mod_load_flow, timestep ='d').sum(axis=0)[0]    \n",
    "df_month = df_month[(df_month.obs != 0) & (df_month.loc[:, 'mod'] != 0)]\n",
    "df_month.index.name = 'Month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.to_csv(f'{outpath}mod_obs_month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the coefficients of variation for concentrations (CVC) and discharge (CVQ), their ratio (CVC:CVQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define timeperiod\n",
    "time_ranges = pd.to_datetime(['2009/7/1', '2018/6/30'])\n",
    "df_cv = pd.DataFrame(columns=['obs', 'mod'], index=['cvc', 'cvq', 'cvl'])\n",
    "start, end = time_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read obs time series of flow, loads and concentration\n",
    "df_obs = load_flow_loc([start, end], day_load_flow, timestep ='d')\n",
    "cv_all = (df_obs.std(axis=0) / df_obs.mean(axis=0))\n",
    "cols = df_obs.columns\n",
    "df_cv.loc[:, 'obs'] = [cv_all[cols[3]], cv_all[cols[2]], cv_all[cols[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mod time series of flow, loads and concentration\n",
    "df_mod = load_flow_loc([start, end], mod_load_flow, timestep ='d')\n",
    "cv_all = (df_mod.std(axis=0) / df_mod.mean(axis=0))\n",
    "cols = df_mod.columns\n",
    "df_cv.loc[:, 'mod'] = [cv_all[cols[1]], cv_all[cols[2]], cv_all[cols[0]]]\n",
    "\n",
    "df_cv.loc['cq', :] = df_cv.loc['cvc', :] / df_cv.loc['cvq', :]\n",
    "df_cv.loc['lq', :] = df_cv.loc['cvl', :] / df_cv.loc['cvq', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.to_csv(f'{outpath}cv_cql.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression of C-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from sklearn.metrics import r2_score\n",
    "from utils.signatures import residual, nonlinear_fit\n",
    "from utils.plotting import regression_plot\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y\n",
    "time_range = [['/7/1', '/10/1'], ['/10/1', '/1/1'], ['/1/1', '/4/1'], ['/4/1', '/7/1']]\n",
    "cols = day_load_flow.columns\n",
    "day_load_flow.loc[:, cols[0]] = day_load_flow.loc[:, cols[0]]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Average_Load(t)</th>\n",
       "      <th>Flow  (Cumecs)</th>\n",
       "      <th>Flow(ML)</th>\n",
       "      <th>Concentration (mg/L)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-01</th>\n",
       "      <td>0.3418</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.019930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-02</th>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.025886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-03</th>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>17.73</td>\n",
       "      <td>0.031799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-04</th>\n",
       "      <td>0.5665</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>15.67</td>\n",
       "      <td>0.036152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-05</th>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>17.23</td>\n",
       "      <td>0.039617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Linear_Average_Load(t)  Flow  (Cumecs)  Flow(ML)  \\\n",
       "Date                                                           \n",
       "2009-07-01                  0.3418          0.1985     17.15   \n",
       "2009-07-02                  0.4530          0.2026     17.50   \n",
       "2009-07-03                  0.5638          0.2052     17.73   \n",
       "2009-07-04                  0.5665          0.1813     15.67   \n",
       "2009-07-05                  0.6826          0.1994     17.23   \n",
       "\n",
       "            Concentration (mg/L)  \n",
       "Date                              \n",
       "2009-07-01              0.019930  \n",
       "2009-07-02              0.025886  \n",
       "2009-07-03              0.031799  \n",
       "2009-07-04              0.036152  \n",
       "2009-07-05              0.039617  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_load_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict, y_dict = {}, {}\n",
    "k = 1\n",
    "for tt in time_range:\n",
    "    x, y = np.array([]), np.array([])\n",
    "    for year in range(2009, 2019):\n",
    "        start = pd.to_datetime(f'{year}{tt[0]}')\n",
    "        if tt[1] == '/1/1':\n",
    "            end = pd.to_datetime(f'{year+1}{tt[1]}') - datetime.timedelta(days=1)\n",
    "        else:\n",
    "            end = pd.to_datetime(f'{year}{tt[1]}') - datetime.timedelta(days=1)\n",
    "        df_temp = load_flow_loc([start, end], day_load_flow, timestep ='d')\n",
    "        x = np.append(x, df_temp.values[:, 2])\n",
    "        y = np.append(y, df_temp.values[:, 0])\n",
    "    x_dict[f'{k}_x'] = x\n",
    "    x_dict[f'{k}_y'] = y\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Improper input: N=3 must not exceed M=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-acb7c00a1a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlmfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mout1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnonlinear_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopti_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'differential_evolution'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# lmfit, x=x_input, y=y_output,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# compare coefficient of determination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\cloudStor\\Projects\\oed_data\\wqd_analyze\\src\\utils\\signatures.py\u001b[0m in \u001b[0;36mnonlinear_fit\u001b[1;34m(p, func, x, y, opti_method)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m# then solve with Levenberg-Marquardt using the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# differential_evolution solution as a starting point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mout2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'leastsq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mlmfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\oed\\lib\\site-packages\\lmfit\\minimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, method, params, **kws)\u001b[0m\n\u001b[0;32m   2361\u001b[0m                         val.lower().startswith(user_method)):\n\u001b[0;32m   2362\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\oed\\lib\\site-packages\\lmfit\\minimizer.py\u001b[0m in \u001b[0;36mleastsq\u001b[1;34m(self, params, max_nfev, **kws)\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_kws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlskws\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1700\u001b[1;33m             \u001b[0mlsout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy_leastsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__residual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlskws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1701\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAbortFitException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\oed\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36mleastsq\u001b[1;34m(func, x0, args, Dfun, full_output, col_deriv, ftol, xtol, gtol, maxfev, epsfcn, factor, diag)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Improper input: N=%s must not exceed M=%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepsfcn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Improper input: N=3 must not exceed M=0"
     ]
    }
   ],
   "source": [
    "# variables are x and y\n",
    "coeff_regress = pd.DataFrame(columns = np.arange(1, 5), index=['R2', 'a', 'b', 'c'])\n",
    "for k in range(1, 5):\n",
    "    x = x_dict[f'{k}_x']\n",
    "    y = x_dict[f'{k}_y']\n",
    "    p = lmfit.Parameters()\n",
    "    p.add_many(('a', 0.1, True, 0, 10), ('b', 2, True, 0, 2 ), ('c', 1, True, -1, 10))\n",
    "    out1, out2, ci, trace = nonlinear_fit(p, residual, x, y, opti_method='differential_evolution')# lmfit, x=x_input, y=y_output,\n",
    "\n",
    "    # compare coefficient of determination\n",
    "    para_values = {}\n",
    "    for param in ['a', 'b', 'c']: \n",
    "        para_values[param] = np.round(trace['a'][param][0], 4)\n",
    "    y_mod = para_values['a'] * x ** para_values['b']+ para_values['c']\n",
    "    r2 = r2_score(np.log(y), np.log(y_mod))\n",
    "    abs_bias = np.abs(np.average(y_mod - y))\n",
    "    rel_bias = abs_bias / np.average(y)\n",
    "    coeff_regress.loc[:, k] = [r2, para_values['a'], para_values['b'], para_values['c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.752752</td>\n",
       "      <td>0.820016</td>\n",
       "      <td>0.860539</td>\n",
       "      <td>0.535238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1.286800</td>\n",
       "      <td>1.090700</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>1.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.472800</td>\n",
       "      <td>0.498800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4\n",
       "R2  0.752752  0.820016  0.860539  0.535238\n",
       "a   0.044400  0.283800  0.123600  0.152800\n",
       "b   1.286800  1.090700  1.024100  1.081400\n",
       "c   0.000000  0.000000  6.472800  0.498800"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_regress.to_csv(outpath+'obs_cq_regress.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the variation of delivery ratio -surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read observations, modeled outputs with delivery ratio at 0 and 25 (%)\n",
    "mod_fl_fn = 'DIN_flow_DRS0.csv'\n",
    "mod_drs0 = pd.read_csv(modpath + mod_fl_fn, index_col='Date')\n",
    "mod_drs0.index = pd.to_datetime(mod_drs0.index, dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = pd.DataFrame(columns=['mod_drs0'])\n",
    "# calculate the monthly loads and flow\n",
    "for y in range(2009, 2019):\n",
    "    for m in range(1, 13):\n",
    "        start = pd.to_datetime(f'{y}/{m}/1')\n",
    "        if m == 12:\n",
    "            end = pd.to_datetime(f'{y+1}/1/1') - datetime.timedelta(days=1) \n",
    "        else:\n",
    "            end = pd.to_datetime(f'{y}/{m+1}/1') - datetime.timedelta(days=1)\n",
    "        df_month.loc[f'{y}/{m}', 'mod_drs0'] = load_flow_loc([start, end], mod_drs0, timestep ='d').sum(axis=0)[0]    \n",
    "df_month = df_month[(df_month.loc[:, 'mod_drs0'] != 0)]\n",
    "df_month.index.name = 'Month'\n",
    "df_month.to_csv(outpath+'mod_month_drs0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mod_month = pd.read_csv(outpath+'mod_obs_month.csv', index_col='Month')\n",
    "df_concat = pd.concat([obs_mod_month, df_month], axis=1).dropna(axis=0)\n",
    "df_concat['drs'] = (df_concat['obs'] - df_concat['mod_drs0']) / (df_concat['mod'] - df_concat['mod_drs0']) * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv(outpath+'obs_mod_month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ave', 'min', 'max', 'mean_load_first']\n",
    "x_list = [*np.arange(7, 13), *np.arange(1, 7)]\n",
    "drs_stats = pd.DataFrame(columns=cols, index=x_list)\n",
    "drs_stats.index.name = 'month'\n",
    "for i in range(12):\n",
    "    drs_stats.loc[x_list[i], cols[0:3]] = df_concat.drs[i::12].mean(), df_concat.drs[i::12].min(), df_concat.drs[i::12].max()\n",
    "    obs_mod = (df_concat['obs'][i::12].mean() - df_concat['mod_drs0'][i::12].mean())\n",
    "    mod_mod0 = (df_concat['mod'][i::12].mean() - df_concat['mod_drs0'][i::12].mean())\n",
    "    drs_stats.loc[x_list[i], cols[-1]] = obs_mod / mod_mod0 * 25\n",
    "drs_stats.to_csv(outpath+'DeliveryRatioSurface.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oed)",
   "language": "python",
   "name": "oed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

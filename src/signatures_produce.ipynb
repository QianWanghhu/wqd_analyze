{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script is used to caclulate the Event Mean Concentration (EMC).\n",
    "The inputs are .csv files containing concentration and flow after linear interpolation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.concentration import rainfall_events, emc_cal, conc_interpolate, event_emc\n",
    "\n",
    "# read the discrete storm events\n",
    "# Read daily loads and flow\n",
    "# Read hourly loads and flow\n",
    "from common_settings import obspath, outpath, events_name, \\\n",
    "    obs_events, day_load_flow, hour_load_flow, conct_name, modpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the event mean concentration of obs and mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for low-frequency data\n",
    "cols = [col for col in day_load_flow.columns if ('Load' in col) or ('Flow(ML)' in col)]\n",
    "index_range1 = [1, 60]\n",
    "index_range2 = [60, obs_events.shape[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events = event_emc(obs_events, day_load_flow, index_range1, cols[0], cols[1], \n",
    "    time_scale='d', multiplier=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for high-frequency data\n",
    "cols = [col for col in hour_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range2 = [60, obs_events.shape[0]+1]\n",
    "loads_col = cols[1]; flow_col = cols[0]\n",
    "obs_events = event_emc(obs_events, hour_load_flow, index_range2, loads_col, flow_col, \n",
    "    time_scale='h', multiplier=1)\n",
    "obs_events.to_csv(outpath + events_name, index='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the discrete storm events\n",
    "modpath = '../data/mod/'\n",
    "filename = 'storm_event.csv'\n",
    "events = rainfall_events(f'{modpath}{filename}')\n",
    "\n",
    "# Calculate EMC for modeling data\n",
    "mod_fl_fn = 'DIN_flow.csv'\n",
    "load_flow = pd.read_csv(modpath + mod_fl_fn, index_col='Date')\n",
    "load_flow.index = pd.to_datetime(load_flow.index)\n",
    "cols = [col for col in load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range = [1, events.shape[0]]\n",
    "loads_col = cols[0]; flow_col = cols[1]\n",
    "\n",
    "events = event_emc(events, load_flow, index_range, loads_col, flow_col, \n",
    "    time_scale='d', multiplier=1)\n",
    "events.dropna(axis=0, inplace=True)\n",
    "# events.to_csv(f'{outpath}DIN_{filename}', index='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the Normalized cumulative ratio of loads and flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.concentration import cumulative_lq, excel_save\n",
    "from utils.signatures import update_cumul_df, load_flow_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the daily data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2020)]\n",
    "# time_ranges = obs_events.loc[:, ['start', 'end']].values\n",
    "double_mass_ratio = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(0, len(time_ranges)-2):\n",
    "# for ii in range(index_range1[0]-1, index_range1[1]-1):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], day_load_flow, timestep='d')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, 0], df_temp.values[:, -1])\n",
    "    double_mass_ratio[f'obs_year_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outputs into one excel\n",
    "fn = outpath +'obs_year_cumulative_ratio_day.xlsx'\n",
    "excel_save(double_mass_ratio, fn, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the hourly data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_mass_ratio = {}\n",
    "for ii in range(index_range2[0]-1, index_range2[1]-1):\n",
    "# for ii in range(9, len(time_ranges)):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], hour_load_flow, timestep='h')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, -1], df_temp.values[:, 0])\n",
    "    double_mass_ratio[f'obs_storm_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outputs into one excel\n",
    "fn = outpath +'obs_storm_cumulative_ratio_hour.xlsx'\n",
    "excel_save(double_mass_ratio, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the modeling data for double mass plot (Q-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpath = '../data/mod/'\n",
    "filename = 'storm_event.csv'\n",
    "mod_events = rainfall_events(f'{modpath}{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMC for modeling data\n",
    "mod_fl_fn = 'DIN_flow.csv'\n",
    "mod_load_flow = pd.read_csv(modpath + mod_fl_fn, index_col='Date')\n",
    "mod_load_flow.index = pd.to_datetime(mod_load_flow.index)\n",
    "cols = [col for col in mod_load_flow.columns if ('Load' in col) or ('ML' in col)]\n",
    "index_range = [1, mod_events.shape[0]]\n",
    "loads_col = cols[0]; flow_col = cols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_mass_ratio = {}\n",
    "time_ranges = [[f'{year}-07-01', f'{year+1}-06-30'] for year in range(2009, 2014)]\n",
    "# time_ranges = mod_events.loc[:, ['start', 'end']].values\n",
    "# for ii in range(index_range[0], index_range[1]):\n",
    "for ii in range(len(time_ranges)):\n",
    "    df_temp = load_flow_loc(time_ranges[ii], mod_load_flow, timestep='d')\n",
    "    df_temp = update_cumul_df(df_temp, df_temp.values[:, 0], df_temp.values[:, -1])\n",
    "    double_mass_ratio[f'mod_storm_{ii}'] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "fn = outpath +'mod_year_cumulative_ratio_day.xlsx'\n",
    "excel_save(double_mass_ratio, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate event load coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event loads for obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_fn = 'obs_storm_event'\n",
    "obs_events = pd.read_csv(f'{outpath}{obs_event_fn}.csv', index_col = 'ID') \n",
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, calculate the yearly loads \n",
    "year_loads = {}\n",
    "# obs daily data\n",
    "for tt in time_ranges[0:-2]:\n",
    "    df = load_flow_loc(tt, day_load_flow, timestep='d')\n",
    "    year_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  \n",
    "    \n",
    "# obs hourly data\n",
    "for tt in time_ranges[-2:]:\n",
    "    df = load_flow_loc(tt, hour_load_flow, timestep='h')\n",
    "    year_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event load coefficients\n",
    "for ii in range(1, index_range1[1]):\n",
    "    df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, day_load_flow, timestep='d')\n",
    "    ymd= pd.to_datetime(obs_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year - 1)]\n",
    "    else:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year)]\n",
    "        \n",
    "for ii in range(index_range2[0], index_range2[1]):\n",
    "    df_event = load_flow_loc(obs_events.loc[ii, 'start':'end'].values, hour_load_flow, timestep='h')\n",
    "    ymd= pd.to_datetime(obs_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year-1)]\n",
    "    else:\n",
    "        obs_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / year_loads[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_events.to_csv(f'{outpath}{obs_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event loads for mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_event_fn = 'mod_NO3_flow'\n",
    "mod_events = pd.read_csv(f'{outpath}{mod_event_fn}.csv', index_col = 'ID') \n",
    "time_ranges = [[f'{year}/7/1', f'{year+1}/6/30'] for year in range(2009, 2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, calculate the yearly loads \n",
    "mod_loads = {}\n",
    "# obs daily data\n",
    "for tt in time_ranges:\n",
    "    df = load_flow_loc(tt, mod_load_flow, timestep='d')\n",
    "    mod_loads[tt[0][0:4]] = np.round(df.values[:, 0].sum(), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event load coefficients\n",
    "for ii in mod_events.index:\n",
    "    df_event = load_flow_loc(mod_events.loc[ii, 'start':'end'].values, mod_load_flow, timestep='d')\n",
    "    ymd= pd.to_datetime(mod_events.loc[ii, 'start'])\n",
    "    month = ymd.month; year = ymd.year\n",
    "    if month < 7:\n",
    "        mod_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / mod_loads[str(year - 1)]\n",
    "    else:\n",
    "        mod_events.loc[ii, 'event_load_coefficients'] = df_event.values[:, 0].sum() / mod_loads[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_events.to_csv(f'{outpath}{mod_event_fn}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oed)",
   "language": "python",
   "name": "oed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
